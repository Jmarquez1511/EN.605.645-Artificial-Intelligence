{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "When we last left our agent in Module 4, it was wandering around a world filled with plains, forests, swamps, hills and mountains. This presupposes a map with known terrain:\n",
    "\n",
    "```\n",
    "......\n",
    "...**.\n",
    "...***\n",
    "..^...\n",
    "..~^..\n",
    "```\n",
    "\n",
    "but what if all we know is that we have some area of interest, that we've reduced to a GPS grid:\n",
    "\n",
    "```\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "??????\n",
    "```\n",
    "\n",
    "and the agent has to determine what kind of terrain is to the left, front and right of it?\n",
    "\n",
    "Assuming the agent has a very simple visual sensor that constructs a 4x4 grayscale image for each of the three directions, it might it could see something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "plain =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "forest = [0.0, 1.0, 0.0, 0.0,1.0, 1.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0,0.0, 1.0, 0.0, 0.0]\n",
    "hills =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 1.0, 0.0,0.0, 1.0, 1.0, 1.0,1.0, 1.0, 1.0, 1.0]\n",
    "swamp =  [0.0, 0.0, 0.0, 0.0,0.0, 0.0, 0.0, 0.0,1.0, 0.0, 1.0, 0.0,1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "figure = plt.figure(figsize=(20,6))\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 1)\n",
    "pixels = np.array([255 - p * 255 for p in plain], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Left Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 2)\n",
    "pixels = np.array([255 - p * 255 for p in forest], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Front Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "axes = figure.add_subplot(1, 3, 3)\n",
    "pixels = np.array([255 - p * 255 for p in hills], dtype='uint8')\n",
    "pixels = pixels.reshape((4, 4))\n",
    "axes.set_title( \"Right Camera\")\n",
    "axes.imshow(pixels, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which would be plains, forest and hills respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assignment\n",
    "\n",
    "In Assignment 12, we applied a logistic regression to determine if something was \"hills\" or \"not hills\". For this programming assignment your task is to write an artificial neural network that determines what kind of terrain it is. This is a multi-class problem.\n",
    "\n",
    "For a starting point, you can refer to Pseudocode and the Self-Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As before, we have clean examples of the different types of terrain but based on the location, the registration can be a bit off for some of the types and the visual sensor is often blurry.\n",
    "\n",
    "Here are the clean examples with different registrations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = {\n",
    "    \"plains\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"plains\"]\n",
    "    ],\n",
    "    \"forest\": [\n",
    "        [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, \"forest\"],\n",
    "        [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, \"forest\"],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, \"forest\"]\n",
    "    ],\n",
    "    \"hills\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, \"hills\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, \"hills\"]\n",
    "    ],\n",
    "    \"swamp\": [\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, \"swamp\"]        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that allows us to view any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sensor_image( data):\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    axes = figure.add_subplot(1, 1, 1)\n",
    "    pixels = np.array([255 - p * 255 for p in data[:-1]], dtype='uint8')\n",
    "    pixels = pixels.reshape((4, 4))\n",
    "    axes.set_title( \"Left Camera:\" + data[-1])\n",
    "    axes.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I think that I shall never see a thing so lovely as a tree.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAEICAYAAABS/TFyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAARrElEQVR4nO3df7DldV3H8eeLZRXjh5vDFgvLj4otxx8lclshm6LSAsYGm6ygmWjoxxajJlNOmc0g/W6mctJIbEsDJseyDGNszagssES9ywAJm7UKtBur/BAWNhgLePfH94ser5/7Y/d8z7n37n0+Zs7s+Z7v534/n3P23Nf9ns/3e77vVBWSNNcRyz0ASSuT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgyHVSLJ9yXZk+RAkjOWezzTluSlSf6zf/6vXO7xrAWGw5QluTvJyw7hR38HeE1VHQM8lKSSHLlIX1+f5C+SPJBkf5Lbk/xsknWHNPjl9SvAlVV1TFW9b1qd9q/z6dPqbyUxHFaPU4E7lto4ydcBHwX2AC+sqmcDPwDMAMdOZIRLH9uCoTaPg3r+A/SnqvI2xRtwN/CyxuNHAG8APgU8CLwHeA7wTOAAUMD/9Ov/q18+0N/ObmzvT4G/WWQsfwF8BtgP3Ag8f2Td1cDbgA/0ffwLcALwe8BDwL8DZ4y0PxF4L3A/cBfwMyPrrgD+sh/TI8BPAFuBjwAPA/uAK4FnzDPOTwFPAY/3Y3lm39/1wOeA3cBPLtLfs4F39H39N/BrwLq+/enAP/evwwPAn/eP3zjyuh8Afmi53z9Tfa8u9wDW2m2BcLgMuBnY3L/5/xB498j6Ak7v75/WLx+5QD+fAS5ZZCw/RrcX8cz+l/7WkXVX978oZwJHAf/Y/9JfDKzrf7k+1Lc9AtgJXA48A/ha4NPA9/TrrwD+D3hl3/ZZ/XbPAo7sn88u4LKR/t8PvGG+163/ZX5bP7YX0YXSdy3Q3/v61/Ro4KuAjwE/1bd/N/BLfdujgG9tve5r7bbsA1hrtwXCYdfTb+5+eVP/Bj+yXz7YcPg/4NyDGNeGfpvP7pevBv5oZP1rgV0jyy8EHu7vvwT4rznb+0XgT/r7VwA3LtL/ZcB1S3ndgJOBJ4FjR9b/JnB1qz/gq4HPA88aeewivhhu1wLbgc2NftdsOPhZbOU4FbguyVMjjz1J98b+70PY3oN0AdPUT0r+Ot08xEa63XaA4+l2rwE+O/IjjzeWjxkZ+4lJHh5Zvw64aWR5z5z+vx54M90cyFfQ7UHsXOQ5Pe1E4HNV9ejIY/f022r1dyqwHtiX5OnHjhhp8/PArwIfS/IQ8LtV9c4ljuWw5YTkyrEHOK+qNozcjqqqVjAs5au0fw98/wLrfxi4AHgZ3efx0/rHM98PLGAPcNecsR9bVecvMOar6OYttlTVccAbD6Lve4HnJBmdWD2FLw3R0f720O05HD8yvuOq6vkAVfWZqvrJqjoR+CngbWv1CMUow2F5rE9y1MjtSODtwK8nORUgycYkF8zz8/fT/aX/2gX6eBPwLUl+O8kJ/TZPT/KnSTbQzTV8nm4P4yuA3xjj+XwMeCTJLyR5VpJ1SV6Q5JsX+Jlj6SYLDyR5LnDpUjurqj3AvwK/2b9+3wj8OPCuedrvA/4O+N0kxyU5IsnXJfl2gCQ/kGRz3/whumB5sl/+LAu/zoctw2F57KDbLX/6dgXwFrrZ979L8ijd5ORLWj9cVY/RfST4lyQPJzmr0eZTwNl0ewR3JNlPdzRhFniU7nP2PXR/be/s+zskVfUk8L10E4N30U1k/jHdHsl8Xk+39/Io8EfAn4+uTPKBJG9c4Ocvontu9wLXAW+qqhsWaH8x3WTpnXQB8Jd88WPXNwMfTXKA7v/gdVV1V7/uCuCa/nX+wQW2f9hJP+kiSV/CPQdJTWMdrUjyHLrdwdPoDjX9YFU91Gh3N93u45PAE1U1M7eNpJVl3D2HNwD/UFVbgH/ol+fzHVX1IoNBWh3GDYcLgGv6+9fQnZEm6TAw1oRkkoerasPI8kNV9ZWNdnfxxUNEf1hV2xfY5jZgG8DRRx995nOf+9xDHt9KtXPnUs/1WX3OPPPM5R6CDsLdd9/NAw880Dy/ZNFwSPL3dF+4meuXgGuWGA4nVtW9Sb4KuAF4bVXduNjAZ2ZmanZ2drFmq87IWXqHHY9+rS4zMzPMzs4235CLTkhW1bzXHkjy2SSbqmpfkk3AffNs497+3/uSXEf3jbxFw0HS8hl3zuF64Ef7+z8K/PXcBkmOfvo01yRHA98NfGLMfiVN2Ljh8FvAy5P8J/DyfpkkJybZ0bf5auDDSW6jO832b6rqb8fsV9KEjXWeQ1U9CHxX4/F7gfP7+58GvmmcfiRNn2dISmoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUNEg5Jzk3yySS7k3xZ1at03tqvvz3Ji4foV9LkjB0OSdYBfwCcBzwPuCjJ8+Y0Ow/Y0t+2AVeN26+kyRpiz2ErsLuqPl1V/wv8GV2ZvFEXANdW52ZgQ1/nQtIKNUQ4nATsGVne2z92sG0krSBDhEOrlNbcmmhLadM1TLYlmU0ye//99489OEmHZohw2AucPLK8Gbj3ENoAUFXbq2qmqmY2btw4wPAkHYohwuHjwJYkX5PkGcCFdGXyRl0PXNwftTgL2F9V+wboW9KEjFXxCqCqnkjyGuCDwDrgnVV1R5Kf7te/HdhBVwFrN/AYcMm4/UqarLHDAaCqdtAFwOhjbx+5X8Crh+hL0nR4hqSkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqWlatTLPSbI/ya397fIh+pU0OWNfYHakVubL6epTfDzJ9VV155ymN1XVK8btT9J0DHH16S/UygRI8nStzLnhcNB27txJ0iqWpZXqcP3/6i6gvrZMq1YmwNlJbkvygSTPn29jo+XwBhibpEM0xJ7DUupg3gKcWlUHkpwPvA/Y0tpYVW0HtgMkWXtxLa0QU6mVWVWPVNWB/v4OYH2S4wfoW9KETKVWZpIT0n8YTbK17/fBAfqWNCHTqpX5KuDSJE8AjwMX1lqc4ZFWkazk31HnHLRSrOTfk3HMzMwwOzvbPMTkGZKSmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTUOVw3tnkvuSfGKe9Uny1r5c3u1JXjxEv5ImZ6g9h6uBcxdYfx5dnYotwDbgqoH6lTQhg4RDVd0IfG6BJhcA11bnZmBDkk1D9C1pMqY157DUknmWw5NWiCHK4S3FUkrmdQ9aDk9aEaa157BoyTxJK8u0wuF64OL+qMVZwP6q2jelviUdgkE+ViR5N3AOcHySvcCbgPXwhXJ4O4Dzgd3AY8AlQ/QraXIGCYequmiR9QW8eoi+JE2HZ0hKajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNU2rHN45SfYnubW/XT5Ev5ImZ6i6FVcDVwLXLtDmpqp6xUD9SZqwaZXDk7TKTKviFcDZSW6jK2bz+qq6o9UoyTa6YrvSipG0irYd3tJdNX6ADSWnAe+vqhc01h0HPFVVB5KcD7ylqrYsYZuWw5MmrKqayTeVoxVV9UhVHejv7wDWJzl+Gn1LOjRTCYckJ6TfL0uyte/3wWn0LenQTKsc3quAS5M8ATwOXFhDfZ6RNBGDzTlMgnMO0uQt65yDpNXHcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNQ0djgkOTnJh5LsSnJHktc12iTJW5PsTnJ7kheP26+kyRriArNPAD9XVbckORbYmeSGqrpzpM15wJb+9hLgqv5fSSvU2HsOVbWvqm7p7z8K7AJOmtPsAuDa6twMbEiyady+JU3OoHMOfdWrM4CPzll1ErBnZHkvXx4gT29jW5LZJLNDjk3SwRmsVmaSY4D3ApdV1SNzVzd+pHnZ+araDmzvt+ml6aVlMsieQ5L1dMHwrqr6q0aTvcDJI8ub6QrqSlqhhjhaEeAdwK6qevM8za4HLu6PWpwF7K+qfeP2LWlyxq54leRbgZuAfwOe6h9+I3AKdOXw+gC5EjgXeAy4pKoWnVPwY4U0efNVvLIcnrTGWQ5P0kExHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDVNqxzeOUn2J7m1v10+br+SJmta5fAAbqqqVwzQn6QpmFY5PEmrzGAVr2DBcngAZye5ja6Yzeur6o55trEN2AZwyimncM899ww5xBWhu1L/4WklX81cX25mZmbedYNNSC5SDu8W4NSq+ibg94H3zbedqtpeVTNVNbNx48ahhifpIE2lHF5VPVJVB/r7O4D1SY4fom9JkzGVcnhJTujbkWRr3++D4/YtaXKGmHN4KfAjwL8lubV/7EvK4QGvAi5N8gTwOHBh+eFUWtHGDoeq+jCw4AxbVV1JVytT0irhGZKSmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTUNcYPaoJB9LcltfDu+XG22S5K1Jdie5PcmLx+1X0mQNcYHZzwPfWVUH+kvUfzjJB6rq5pE25wFb+ttLgKv6fyWtUEOUw6una1IA6/vb3CtLXwBc27e9GdiQZNO4fUuanKGK2qzrL0t/H3BDVc0th3cSsGdkeS/W05RWtEHCoaqerKoXAZuBrUleMKdJ69L1zboVSbYlmU0ye//99w8xPEmHYNCjFVX1MPBPwLlzVu0FTh5Z3kxXULe1DWtlSivAEEcrNibZ0N9/FvAy4N/nNLseuLg/anEWsL+q9o3bt6TJGeJoxSbgmiTr6MLmPVX1/iQ/DV8oh7cDOB/YDTwGXDJAv5ImaIhyeLcDZzQef/vI/QJePW5fkqbHMyQlNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU3TqpV5TpL9SW7tb5eP26+kyZpWrUyAm6rqFQP0J2kKhrj6dAGL1cqUtMoMsedAX7NiJ3A68AeNWpkAZye5ja7S1eur6o55trUN2NYvHkjyySHGuATHAw9Mqa9pmurzSlqVDyficP3/guk+t1PnW5HuD/8w+spX1wGvrapPjDx+HPBU/9HjfOAtVbVlsI4HkGS2qmaWexxD83mtPivluU2lVmZVPVJVB/r7O4D1SY4fsm9Jw5pKrcwkJ6Tf30yyte/3wXH7ljQ506qV+Srg0iRPAI8DF9aQn2eGsX25BzAhPq/VZ0U8t0HnHCQdPjxDUlKT4SCpac2HQ5Jzk3wyye4kb1ju8QwlyTuT3JfkE4u3Xj2SnJzkQ0l29afrv265xzSEpXwNYepjWstzDv0k6n8ALwf2Ah8HLqqqO5d1YANI8m10Z65eW1UvWO7xDCXJJmBTVd2S5Fi6k+9eudr/z/qjeUePfg0BeF3jawhTs9b3HLYCu6vq01X1v8CfARcs85gGUVU3Ap9b7nEMrar2VdUt/f1HgV3AScs7qvFVZ0V9DWGth8NJwJ6R5b0cBm+0tSLJacAZQOt0/VUnyboktwL3ATfM8zWEqVnr4dD6IsDa/Zy1iiQ5BngvcFlVPbLc4xlCVT1ZVS8CNgNbkyzrx8G1Hg57gZNHljfTfTFMK1j/mfy9wLuq6q+WezxDm+9rCNO21sPh48CWJF+T5BnAhcD1yzwmLaCfuHsHsKuq3rzc4xnKUr6GMG1rOhyq6gngNcAH6Sa23jPfV8lXmyTvBj4CfEOSvUl+fLnHNJCXAj8CfOfIlcXOX+5BDWAT8KEkt9P90bqhqt6/nANa04cyJc1vTe85SJqf4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU3/D6BHLHUKWGetAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[ \"forest\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that comes in, however, is noisy. The values are never exactly 0 and 1. In order to mimic this we need a `blur` function.\n",
    "\n",
    "We will assume that noise is normally distributed. For values that should be 0, the noisy values are distributed $N(0.10, 0.05)$. For values should be 1, the noisy values are distributed $N(0.9, 0.10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur( data):\n",
    "    def apply_noise( value):\n",
    "        if value < 0.5:\n",
    "            v = random.gauss( 0.10, 0.05)\n",
    "            if v < 0.0:\n",
    "                return 0.0\n",
    "            if v > 0.75:\n",
    "                return 0.75\n",
    "            return v\n",
    "        else:\n",
    "            v = random.gauss( 0.90, 0.10)\n",
    "            if v < 0.25:\n",
    "                return 0.25\n",
    "            if v > 1.00:\n",
    "                return 1.00\n",
    "            return v\n",
    "    noisy_readings = [apply_noise( v) for v in data[0:-1]]\n",
    "    return noisy_readings + [data[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this affects what the agent *actually* sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sensor_image( blur( clean_data[\"swamp\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13992819103013804,\n",
       " 0.07882106579017387,\n",
       " 0.16749850638681643,\n",
       " 0.018905550216034753,\n",
       " 0.09675430153256012,\n",
       " 0.22354440573908488,\n",
       " 0.10285456410666129,\n",
       " 0.12756446650264042,\n",
       " 0.9569986605579277,\n",
       " 0.15369567565197748,\n",
       " 0.8066405592640903,\n",
       " 0.16221648409722111,\n",
       " 1.0,\n",
       " 0.6810174324829089,\n",
       " 0.9667032193901781,\n",
       " 1.0,\n",
       " 'swamp']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blur( clean_data[\"swamp\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to want to write four (4) functions:\n",
    "\n",
    "1. `generate_data`\n",
    "2. `learn_model`\n",
    "3. `apply_model`\n",
    "\n",
    "### `generate_data`\n",
    "\n",
    "With the clean examples and the `blur` function, we have an unlimited amount of data for training and testing our classifier, an ANN that determines if a sensor image is hills, swamp, forest or plains.\n",
    "\n",
    "In classification, there is a general problem called the \"unbalanced class problem\". In general, we want our training data to have the same number of classes for each class. This means you should probably generate training data with, say, 100 of each type.\n",
    "\n",
    "But what do we do about the class label with the neural network?\n",
    "\n",
    "In this case, we can do \"one hot\". Instead of `generate_data` outputing a single 0 or 1, it should output a vector of 0's and 1's so that $y$ is now a vector as well as $x$. We can use the first position for hill, the second for swamp, the third for forest and the fourth for plains:\n",
    "\n",
    "```\n",
    "[0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "what am I? swamp.\n",
    "\n",
    "Unlike logistic regression, you should set the *biases* inside the neural network (the implict $x_0$ = 1) because there are going to be lot of them (one for every hidden and output node).\n",
    "\n",
    "`generate_data` now only needs to take how many you want of each class:\n",
    "\n",
    "`generate_data( clean_data, 100)`\n",
    "\n",
    "generates 100 hills, 100 swamp, 100 forest, 100 plains and transforms $y$ into the respective \"one hot\" encoding. You can use the code from Module 12 as a starting point.\n",
    "\n",
    "### `learn_model`\n",
    "\n",
    "`learn_model` is the function that takes in training data and actually learns the ANN. If you're up to it, you can implement a vectorized version using Numpy but you might start with the loopy version first.\n",
    "\n",
    "*In the lecture, I mentioned that you usually should mean normalize your data but you don't need to do that in this case because the data is already on the range 0-1.*\n",
    "\n",
    "You should add a parameter to indicate how many nodes the hidden layer should have.\n",
    "\n",
    "When verbose is True, you should print out the error so you can see that it is getting smaller.\n",
    "\n",
    "When developing your algorithm, you need to watch the error so you'll set verbose=True to start. You should print it out every iteration and make sure it is declining. You'll have to experiment with both epsilon and alpha; and it doesn't hurt to make alpha adaptive (if the error increases, make alpha = alpha / 10).\n",
    "\n",
    "When you know that your algorithm is working, change your code so that the error is printed out only every 1,000 iterations (it takes a lot of iterations for this problem to converge, depending on your parameter values--start early).\n",
    "\n",
    "`learn_model` returns the neural network. The hidden layer will be one vector of thetas for each hidden node. And the output layer will have its own thetas, one for each output (4 in this case). Return it as a Tuple: (List of List, List of List).\n",
    "\n",
    "### `apply_model`\n",
    "\n",
    "`apply_model` takes the ANN (the model) and either labeled or unlabeled data. If the data is unlabeled, it will return predictions for each observation as a List of Tuples of the inferred value (0 or 1) and the actual probability (so something like (1, 0.73) or (0, 0.19) so you have [(0, 0.30), (1, 0.98), (0, 0.87), (0, 0.12)]. Note that unlike the logistic regression, the threshold for 1 is not 0.5 but which value is largest (0.98 in this case).\n",
    "\n",
    "If the data is labeled, you will return a List of List of Tuples of the actual value (0 or 1) and the predicted value (0 or 1). For a single data point, you'll have the pairs of actual values [(0, 1), (0, 0), (0, 0), (1, 0)] is a misclassification and [(0, 0), (0, 0), (1, 1), (0, 0)] will be a correct classification. Then you have a List of *those*, one for each observation.\n",
    "\n",
    "###  simple evaluation\n",
    "\n",
    "We have an \"unlimited\" supply of data so we'll just generate a training set and then a test set and see how well our neural network does. Use the error rate (incorrect classifications/total examples) for your evaluation metric. We'll learn about more sophisticated \n",
    "\n",
    "1. generate training set (how many do you think you need?)\n",
    "2. generate test set (how many is a good \"test\" of the network you built?)\n",
    "3. loop over [2, 4, 8] hidden nodes:\n",
    "    1. train model and apply to train data, calculate error rate.\n",
    "    2. apply to test data and calculate error rate.\n",
    "    3. print error rate\n",
    "    \n",
    "Which number of hidden nodes did best?\n",
    "\n",
    "**As always when working with Lists or Lists of Lists, be very careful when you are modifying these items in place that this is what you intend (you may want to make a copy first)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Put your helper functions above here.\n",
    "\n",
    "## Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_data\n",
    "\n",
    "Generates an endless supply of blurred data from a collection of terrain prototypes.\n",
    "\n",
    "* `data`: Dict[Str, List[Any]] - a Dictionary of \"clean\" prototypes for each landscape type.\n",
    "* `n`: Int - the number of blurred examples of each terrain type to return.\n",
    "\n",
    "returns\n",
    "\n",
    "* List[List[Any]] - a List of Lists. Each individual List is a blurred example of a terrain type, generated from the prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data(data, n):\n",
    "    sample_data = []\n",
    "    encoder = {}\n",
    "    encoding = [0 for surface in data.keys()]\n",
    "    for i, surface in enumerate(data.keys()):\n",
    "        \n",
    "        # create encoding sample\n",
    "        surface_encoding = encoding.copy()\n",
    "        surface_encoding[i] = 1\n",
    "        encoder[surface] = surface_encoding\n",
    "        \n",
    "        n_surface_samples = len(data[surface])\n",
    "        if n_surface_samples>1:\n",
    "            new_n = n//n_surface_samples + 1\n",
    "            for s in data[surface]:\n",
    "                for n_ in range(new_n):\n",
    "                    sample_data.append([blur(s)[:-1],encoder[surface]])\n",
    "        else:\n",
    "            new_n = n\n",
    "            for n_ in range(new_n):\n",
    "                    sample_data.append([blur(data[surface][0])[:-1],encoder[surface]])\n",
    "            \n",
    "    return sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "sample = generate_data(clean_data, 100)  \n",
    "# The function generates a total of n * number of suface types in clean data\n",
    "assert len(sample) >= len(clean_data)*n\n",
    "# each observation has an observation and an encoding of the y\n",
    "assert len(sample[0]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learn_model\n",
    "\n",
    "**put documentation here based on the assignment description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `create_network(n_inputs, n_hidden_nodes, n_outputs)`\n",
    "`create_network()` initializes the neural network. The neural network will have the initial components,\n",
    "first it will have a hidden layer. The `hidden_layer` will be constructed taking into account the number of inputs `n_inputs` and the number of hidden nodes `n_hidden_nodes`. This because we need to initialize weights for every connection between `n_inputs` and `n_hidde_nodes`. Similarly, the `output_layer` will initialize weights connecting the number of `n_hidden_nodes` and the number of `n_outputs`. Notice that we are initializing using +1 as we are accounting for the bias of each node. The initalization will be random using the `random` module of the `random` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(n_inputs, n_hidden_nodes, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random.random() for i in range(n_inputs + 1)]} for i in range(n_hidden_nodes)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random.random() for i in range(n_hidden_nodes + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we initialize a network with one input, two hidden layer nodes, and two outputs\n",
    "sample_network = create_network(1, 2, 2)\n",
    "# this node should have a hidden layer of length 2\n",
    "assert len(sample_network[0]) == 2\n",
    "# the first hidden layer node should have two weights, one for the connection to the input and one for the bias\n",
    "assert len(sample_network[0][0]['weights']) == 2\n",
    "# this first output layer should have three weights: one for each hidden layer node, and one for the bias\n",
    "assert len(sample_network[1][0]['weights']) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propagation\n",
    "\n",
    "##### `activate(weights, inputs)`\n",
    "The first step in the feed_forward sequence is to compute the activation function. The `activation()` function takes all the `weights` but the bias and multiplies it against the `inputs` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0,0.5,0.5]\n",
    "inputs = [1,2,1]\n",
    "assert activate(weights, inputs) == 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `transfer_function(activation)`\n",
    "We will implement the sigmoid function of the form $f(x) = \\frac{1}{1 + e^{x}}$ as in the lectures, `transfer_function()` therefore returns the sigmoid function for a given `activation` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "def transfer_function(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of the transfer function for the values 0,1,2\n",
    "assert transfer_function(0) == 0.5\n",
    "assert transfer_function(1) == 0.7310585786300049\n",
    "assert transfer_function(2) == 0.8807970779778823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `forward_propagate(network, row)`\n",
    "During the forward propagation each layer from `network` is looped through\n",
    "while calculating the outputs for each `neuron`. All inputs from one layer become inputs to the neurons at the next layer. The function `forward_propagate` performs this function with a couple of for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer_function(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outputs = 4\n",
    "sample_network = create_network(2, 1, n_outputs)\n",
    "output = forward_propagate(sample_network, [0,1])\n",
    "assert len(output) == n_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation\n",
    "\n",
    "##### transfer_derivative(output)\n",
    "The transfer derivative of an output corresponds to $\\text{transfer derivative} = output \\times (1 - output)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert transfer_derivative(0) == 0\n",
    "assert transfer_derivative(1) == 0\n",
    "assert transfer_derivative(2) == -2\n",
    "assert transfer_derivative(3) == -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `backward_propagate_error(network, expected)`\n",
    "The error on a given output neuron is given by \n",
    "$$\n",
    "error = (output - expected) * \\text{transfer_derivative}(output)\n",
    "$$\n",
    "This error calculation is used for neurons in the output layer.\n",
    "In the inner layer however, the error signal for a neuron is calculated as the weighted error of each neuron in the output layer. \n",
    "For a given $i$th neuron, the weight $j$ will connect the $j$th neuron to the current neuron. The function outputs the output of the current neuron as follows:\n",
    "$$\n",
    "error = (weight_i \\times error_j) * \\text{transfer_derivative}(output)\n",
    "$$\n",
    "The function `backward_propagate_error()` accumulates this error for a given `network` and a set of `expected` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(neuron['output'] - expected[j])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    "           [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "expected = [0, 1]\n",
    "backward_propagate_error(network, expected)\n",
    "# each layer neuron should contain an output, a weight, and a delta value\n",
    "for layer in network:\n",
    "    for node in layer:\n",
    "        assert 'output' in node.keys()\n",
    "        assert 'weights' in node.keys()\n",
    "        assert 'delta' in node.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `update_network(network, row, l_rate)`\n",
    "Next, we need to update the weights given the `delta` value produced in `backward_propagate_error`. `update_network(network, row, l_rate)` updates the weights for a `network` given an input `row` of data, a learning rate `l_rate` and assume that a forward and backward propagation have already been performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] -= l_rate * neuron['delta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `learn_model( data, hidden_nodes, verbose=False, n_epoch=40, l_rate=0.5)`\n",
    "The function `learn_model()` below implements stochastic gradient descent. The expected number of output values is used to transform class values in the training data into a one hot encoding. That is a binary vector with one column for each class value to match the output of the network. This is required to calculate the error for the output layer. The function involves first looping over a fixed number of epochs and within each epoch updating the network for each row in the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def learn_model( data, hidden_nodes, verbose=False, n_epoch=40, l_rate=0.5):\n",
    "    x = [observation[0] for observation in data]\n",
    "    y = [observation[1] for observation in data]\n",
    "    n_inputs = len(x[0])\n",
    "    n_outputs = len(y[0])\n",
    "    network = create_network(n_inputs, hidden_nodes, n_outputs)\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in range(len(x)):\n",
    "            outputs = forward_propagate(network, x[row])\n",
    "            expected = y[row]\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, x[row], l_rate)\n",
    "        if verbose:\n",
    "            print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.500, error=100.372\n",
      ">epoch=1, lrate=0.500, error=116.032\n",
      ">epoch=2, lrate=0.500, error=115.980\n",
      ">epoch=3, lrate=0.500, error=115.528\n",
      ">epoch=4, lrate=0.500, error=113.896\n",
      ">epoch=5, lrate=0.500, error=105.659\n",
      ">epoch=6, lrate=0.500, error=95.214\n",
      ">epoch=7, lrate=0.500, error=88.680\n",
      ">epoch=8, lrate=0.500, error=84.267\n",
      ">epoch=9, lrate=0.500, error=79.035\n",
      ">epoch=10, lrate=0.500, error=69.850\n",
      ">epoch=11, lrate=0.500, error=59.028\n",
      ">epoch=12, lrate=0.500, error=50.866\n",
      ">epoch=13, lrate=0.500, error=45.201\n",
      ">epoch=14, lrate=0.500, error=41.021\n",
      ">epoch=15, lrate=0.500, error=37.377\n",
      ">epoch=16, lrate=0.500, error=33.914\n",
      ">epoch=17, lrate=0.500, error=30.612\n",
      ">epoch=18, lrate=0.500, error=27.565\n",
      ">epoch=19, lrate=0.500, error=24.794\n",
      ">epoch=20, lrate=0.500, error=22.245\n",
      ">epoch=21, lrate=0.500, error=19.905\n",
      ">epoch=22, lrate=0.500, error=17.794\n",
      ">epoch=23, lrate=0.500, error=15.996\n",
      ">epoch=24, lrate=0.500, error=14.495\n",
      ">epoch=25, lrate=0.500, error=13.216\n",
      ">epoch=26, lrate=0.500, error=12.117\n",
      ">epoch=27, lrate=0.500, error=11.165\n",
      ">epoch=28, lrate=0.500, error=10.340\n",
      ">epoch=29, lrate=0.500, error=9.628\n",
      ">epoch=30, lrate=0.500, error=9.013\n",
      ">epoch=31, lrate=0.500, error=8.477\n",
      ">epoch=32, lrate=0.500, error=7.994\n",
      ">epoch=33, lrate=0.500, error=7.547\n",
      ">epoch=34, lrate=0.500, error=7.122\n",
      ">epoch=35, lrate=0.500, error=6.717\n",
      ">epoch=36, lrate=0.500, error=6.332\n",
      ">epoch=37, lrate=0.500, error=5.972\n",
      ">epoch=38, lrate=0.500, error=5.641\n",
      ">epoch=39, lrate=0.500, error=5.339\n"
     ]
    }
   ],
   "source": [
    "sample = generate_data(clean_data, 100)\n",
    "sample_network = learn_model( sample, 4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply_model\n",
    "\n",
    "**put documentation here based on the assignment description**\n",
    "\n",
    "#### `predict_class(model,row)`\n",
    "`predict_class(model,row)` implements `forward_propagate()` from the already trained model into the test dataset. This would generate results for which the arg max value is given the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, row):\n",
    "    output = forward_propagate(sample_network, row)\n",
    "    predicted_class = output.index(max(output))\n",
    "    prediction = [(1 if i == predicted_class else 0, output[i]) for i in range(len(output))]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `apply_model(model, data, labeled= False)`\n",
    "Implements the function as specified in the statement. It loops over the observations in the data to produce predictions using the `predict_class()` function above. If `labeled` is True, then a direct comparison against the provided expected value is produced as the tuple value pair, otherwise a probability is provided as a tuple value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model, data, labeled= False):\n",
    "    x = [observation[0] for observation in data]\n",
    "    y_hat = []\n",
    "    for row in range(len(data)):\n",
    "        y_hat.append(predict_class(model, x[row]))\n",
    "    if labeled:\n",
    "        comparison = []\n",
    "        y = [observation[1] for observation in data]\n",
    "        for row in range(len(y)):\n",
    "            comparison.append([(y[row][label],y_hat[row][label][0]) for label in range(len(y[row]))])\n",
    "        return comparison\n",
    "    else:\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out generate_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0791438574480991, 0.07870481547524914, 0.047950231397511436, 0.18752796867983088, 0.13138220118540853, 0.06717740913029105, 0.06610457578327616, 0.05473720920276186, 0.04486137652846586, 0.09528443211704873, 0.05525179686042726, 0.04361313261071989, 1.0, 0.9141770334360152, 0.8621936137941624, 0.8949425029229924], [1, 0, 0, 0]]\n",
      "[[0.0328150225610402, 0.10437056838427161, 0.029736138758240424, 0.0828142490922946, 0.007018348526731208, 0.18255030646080528, 0.18917133072378098, 0.05002854976132768, 0.12257799504803099, 0.10661615142073326, 0.11968406387110633, 0.03604687117395361, 0.7089347601002686, 0.9902763133398701, 0.8248994929862445, 0.9765765289469768], [1, 0, 0, 0]]\n",
      "[[0.13721136905956619, 0.13830414125775606, 0.07911380332709517, 0.06860846716487734, 0.10094746713339561, 0.10703446080744165, 0.016997559310813926, 0.005548335643702482, 0.10550811808461666, 0.06110927641983832, 0.1075847105479499, 0.019273747503133126, 0.8266611805199703, 1.0, 0.6804921391691294, 0.9634958579494532], [1, 0, 0, 0]]\n",
      "[[0.12146812790563943, 0.15141903115553382, 0.0, 0.08834976794014601, 0.02318712106842742, 0.08008730399816301, 0.17441757929921564, 0.067601449083854, 0.1219005646300544, 0.03295362695180795, 0.11475611829562737, 0.11041000609849637, 0.8746095622882113, 0.9688422504749561, 1.0, 0.7606683000410993], [1, 0, 0, 0]]\n",
      "[[0.1100275325658809, 0.13719227835501902, 0.10786516367265679, 0.1270618433301481, 0.25998312107951144, 0.0, 0.13469858429955328, 0.093100578118747, 0.1078504241387287, 0.07299196010686801, 0.18317268913855503, 0.12095917270087861, 0.776110514595754, 0.8542839352834071, 0.8913947902110918, 1.0], [1, 0, 0, 0]]\n",
      "[[0.1235727174976669, 0.109900486895742, 0.06302017943137136, 0.14099524819703352, 0.16618644009186329, 0.0, 0.09806835493888155, 0.10214649592045108, 0.1392390036068271, 0.1345541076350165, 0.05431568544761842, 0.037166383594974775, 0.7938933173089774, 1.0, 1.0, 0.7653536454328497], [1, 0, 0, 0]]\n",
      "[[0.10476638070786079, 0.046839751121662825, 0.05632829370952323, 0.07972238304002607, 0.09741598656860827, 0.13399039897451567, 0.16627739195218166, 0.05210653212466313, 0.06295635116341725, 0.07052560683958446, 0.08710277987488324, 0.09769131116770235, 0.8198324910150515, 1.0, 0.8594617809939828, 0.7781882846453003], [1, 0, 0, 0]]\n",
      "[[0.1980978921954461, 0.0989482402961783, 0.09087313980636885, 0.07397719893134401, 0.1065451134201771, 0.07415294534041256, 0.17795339828730294, 0.08889629970681409, 0.04823161463897731, 0.10945267467276634, 0.18400024941677695, 0.06778707279465723, 0.8988022228824118, 1.0, 0.7726599146106841, 0.8274547264199639], [1, 0, 0, 0]]\n",
      "[[0.09804123542571926, 0.05992122350648227, 0.15466925008366036, 0.061999071313147046, 0.11452985988468847, 0.1058037464221528, 0.1983086528597392, 0.07603448527167551, 0.03321948536435593, 0.056442638014219365, 0.09195228724292337, 0.10603400439077615, 0.8432563212533292, 1.0, 0.9335127508601191, 1.0], [1, 0, 0, 0]]\n",
      "[[0.04235415258156634, 0.07760214943983945, 0.13423999571089745, 0.055950675655149634, 0.1315611773760691, 0.1331072195061859, 0.13882828604727218, 0.07072970638847315, 0.09465083470158098, 0.03960441143176005, 0.0024851414485003442, 0.16234304027769192, 0.9572335881436396, 0.8304616341030046, 0.8968962787689437, 0.8679392621560386], [1, 0, 0, 0]]\n",
      "[[0.11701632272417842, 1.0, 0.09849445142002049, 0.024304849238504483, 0.8834049695768783, 0.763355928814954, 0.7845422958208108, 0.07922442374623592, 0.859749467533388, 0.9255690121725417, 0.7810683872691049, 0.8286960774460734, 0.11638166891990008, 1.0, 0.016320695986826922, 0.022419740446377553], [0, 1, 0, 0]]\n",
      "[[0.17792879487263583, 1.0, 0.1167764186432684, 0.1899778407729952, 0.8790385031487444, 0.9446674396680022, 0.928870289480547, 0.1621410721752886, 0.7382484990533569, 0.8295355681731916, 0.9760374748816706, 0.9032951441956928, 0.09295903196510617, 0.8947299159476685, 0.18635714948364965, 0.06291826268030179], [0, 1, 0, 0]]\n",
      "[[0.1626172273158778, 0.7751313236893076, 0.042711071912076785, 0.030728442318599433, 1.0, 0.8168412361130725, 0.8542044002266044, 0.12371380586113243, 0.828032115579063, 0.9964292924046423, 0.6928140228832689, 0.8580359086698194, 0.11527101179161198, 0.8110345844833273, 0.1807107737167553, 0.11033773934409633], [0, 1, 0, 0]]\n",
      "[[0.10680760644162746, 0.03874767402085749, 1.0, 0.08477923359594361, 0.011793243957659322, 0.8349980897002706, 0.9232719864374214, 0.9011829063802423, 0.9002735175070407, 0.8722051629770531, 0.99576428793128, 0.9196293321910577, 0.17168928422855376, 0.18045270135956012, 1.0, 0.09925689814888848], [0, 1, 0, 0]]\n",
      "[[0.1380087794143121, 0.07421977953209695, 1.0, 0.12922330181324654, 0.078921951235314, 0.7694289389282335, 0.7793853338517636, 0.9159281549966142, 0.9263665173444426, 1.0, 0.9890553018895962, 0.8350425372570656, 0.11913354398384829, 0.06608222634522148, 0.8238997930066121, 0.048462215079506904], [0, 1, 0, 0]]\n",
      "[[0.03397244664249109, 0.10572109064155327, 0.986624599395094, 0.13235516550559237, 0.150583538550476, 0.9537277486905795, 0.7776149165797517, 1.0, 0.8802277405063664, 0.837723042403661, 0.8918989339464062, 1.0, 0.1444245525927542, 0.12254941706338665, 0.8494697311362938, 0.06976056913482402], [0, 1, 0, 0]]\n",
      "[[0.9541706458685293, 0.07864473609214093, 0.1223650957041853, 0.135497086190196, 0.7921218665489866, 1.0, 0.09431740005879775, 0.14386146934478414, 0.8480439004248348, 0.7525598350996234, 0.8180333782443772, 0.11708566753001556, 0.9903421754614308, 0.11654081444897514, 0.06831775767666147, 0.07522355395333834], [0, 1, 0, 0]]\n",
      "[[1.0, 0.03323532960495493, 0.06711299808154053, 0.07146797341095329, 0.8306723303281092, 0.9214796038747257, 0.09967580737234984, 0.1521695266369028, 0.8895103001772114, 0.9704177980290829, 0.7688270260602054, 0.11252629767878462, 0.7958582331880337, 0.07297276942351184, 0.08409748940857158, 0.0], [0, 1, 0, 0]]\n",
      "[[0.9092253194836896, 0.060512034369564274, 0.08424854229088348, 0.044953091323886876, 0.7982873653202149, 0.9099809330517702, 0.05606980336182758, 0.21343650112249551, 0.8722724446801683, 0.8950515626515718, 0.8376973899889095, 0.1410572616559885, 0.9005539707136528, 0.11633702939457492, 0.09535829953793928, 0.06336267969760101], [0, 1, 0, 0]]\n",
      "[[0.19242847240651897, 0.10402861387157317, 0.09887408977951691, 0.903828940640685, 0.027158305135393176, 0.15449345368203557, 1.0, 0.6511100143668344, 0.04532543526093405, 0.983982668361016, 0.8163731684627612, 0.9528390954708773, 0.0906416463421213, 0.14123326026020921, 0.10777023928780463, 0.8728545730448817], [0, 1, 0, 0]]\n",
      "[[0.04897981846991867, 0.12113805440653631, 0.052960642810385324, 0.8376482029504582, 0.09224204196498921, 0.07729802974243755, 0.9886510695505772, 0.945376787359627, 0.1294986511039268, 0.8059594050182182, 0.9403088226262347, 0.6685503148220209, 0.12346489861094351, 0.1707503696155836, 0.07952526996884754, 0.8242153555841627], [0, 1, 0, 0]]\n",
      "[[0.13452606306001968, 0.04367158979195246, 0.0963015717074378, 0.8939037755315289, 0.11533220155535791, 0.09117651611833466, 1.0, 0.9173927729611522, 0.04499551697547203, 0.8478347574774129, 0.716769212152935, 1.0, 0.18777350920640326, 0.12482077355530566, 0.06855825233654128, 0.813844636464445], [0, 1, 0, 0]]\n",
      "[[0.15860315666544933, 0.1447894017900596, 0.1562841556976306, 0.17067607154709435, 0.07794376564619435, 0.038190102088529125, 1.0, 0.11808909201067809, 0.14460272701758764, 0.8470892233056693, 0.97651962120367, 0.8323235397230118, 0.8623378633302129, 0.8775500957628519, 0.8049345715188587, 0.9298705954540619], [0, 0, 1, 0]]\n",
      "[[0.037202854405804994, 0.09827733408549809, 0.11852236393128364, 0.06614953809353478, 0.11598083360240131, 0.08993355190901847, 0.7997206389716264, 0.0945061546089895, 0.06720307432573241, 0.8929911257579867, 0.7191680411996129, 0.964766306672654, 1.0, 0.9867917737678437, 1.0, 0.9351772445843436], [0, 0, 1, 0]]\n",
      "[[0.09212611289949825, 0.056318214398882696, 0.12868689373624104, 0.01937406182735582, 0.020327222346086277, 0.0925284240441194, 0.8026120553332976, 0.15295146790060324, 0.13151979668341185, 0.8633195438100955, 0.9086709101304407, 0.6338324000554754, 0.8993539997556907, 0.8460615370077892, 0.9792684604470097, 0.8836239150478693], [0, 0, 1, 0]]\n",
      "[[0.0793371464893903, 0.20040855347253816, 0.1407589951689604, 0.09259267275503243, 0.09394714856565473, 0.8254514113849704, 0.10877577212113669, 0.14638361017112483, 0.9051019265770259, 0.7263042757139955, 0.8678649285278407, 0.07008291006340124, 0.9045055682718797, 1.0, 0.8666047371197488, 0.9760749036492746], [0, 0, 1, 0]]\n",
      "[[0.1213644772458464, 0.0855251424054087, 0.1329231535316385, 0.10947320515152348, 0.04226309637889826, 0.9164988304656222, 0.06245186280366577, 0.03400846414020267, 0.8752540739743091, 0.9960776155615997, 0.8085590150070419, 0.1354857429528338, 0.83290828126271, 0.9306432376783347, 0.9040813625768642, 0.8316743407030954], [0, 0, 1, 0]]\n",
      "[[0.021015297148997927, 0.213898543331346, 0.13155463348831747, 0.13674547292224984, 0.1089893075328895, 0.7658089267524484, 0.06336297056755995, 0.12384972558640339, 0.8646883012469226, 0.7425193045935904, 0.9102354595330556, 0.10183981521197487, 0.8779487865220936, 0.9803646677811827, 0.7032859265343447, 0.8651912464807626], [0, 0, 1, 0]]\n",
      "[[0.16580676778910958, 0.10089344976726201, 0.07951119168314631, 0.06791898748501288, 0.7748375235235121, 0.10724237570374318, 0.0, 0.13522555794607832, 0.8719753856299204, 0.9220862276978214, 0.08393465753227931, 0.0879295323248135, 0.7863842532466091, 0.9309148551198756, 1.0, 0.06451681488244285], [0, 0, 1, 0]]\n",
      "[[0.07751537096977633, 0.07757422914836769, 0.07934654026268292, 0.0419558209546069, 0.8712863649110113, 0.08340576103485879, 0.10795208189145378, 0.026416770753113508, 1.0, 0.8611723927474875, 0.06479666497492453, 0.1412998140148087, 1.0, 0.9801183216513234, 0.8899145600006344, 0.07949435662058701], [0, 0, 1, 0]]\n",
      "[[0.039222432273211205, 0.08109605152719176, 0.06940388110002874, 0.14871953023195497, 0.8573252547940576, 0.1497693656636394, 0.019522886407951245, 0.06631835208828067, 0.9479769843551963, 0.8446236003806975, 0.10724356702575713, 0.064706595736429, 0.9923299798360865, 1.0, 0.9897095018203632, 0.15129370299060035], [0, 0, 1, 0]]\n",
      "[[0.009512463320013084, 0.06194547650667556, 0.07289575168529182, 0.14745911232529618, 0.02875120409458387, 0.06927534532705189, 0.04977450968251991, 0.8167575876941733, 0.14826907083314572, 0.019842569053190456, 1.0, 0.819910607379301, 0.13706251757800703, 0.9939491944906567, 0.7272770860585915, 0.9165746184051792], [0, 0, 1, 0]]\n",
      "[[0.11551335805048456, 0.09700173068377506, 0.18121541009713538, 0.14658992136045007, 0.1306134173908225, 0.13272133603506106, 0.04889461150612302, 0.9572001149499048, 0.09150965292515235, 0.08016349920972815, 1.0, 0.9806123720384669, 0.09079705407814889, 0.891775459623718, 0.7824604213932402, 1.0], [0, 0, 1, 0]]\n",
      "[[0.20006705628094268, 0.16165372470544265, 0.13104750588976113, 0.06141439267369106, 0.017797223832775294, 0.17280503017859855, 0.04264949821371022, 0.9946402715177574, 0.029837963247175248, 0.06660848082749987, 0.9928550838255173, 1.0, 0.12001283867861813, 0.8589286739660243, 1.0, 0.7879348802561166], [0, 0, 1, 0]]\n",
      "[[0.15252156197617023, 0.151534060122882, 0.04685872227651722, 0.01728388065543998, 0.07069911051436055, 0.20107337269185724, 0.10180555394437237, 0.023374953633145762, 0.9577010315396396, 0.1813226567219261, 1.0, 0.05948860931591039, 0.9297181013892759, 0.8430670248562105, 0.8397406979669005, 0.9224813240307252], [0, 0, 0, 1]]\n",
      "[[0.12235152104595935, 0.08906889993853297, 0.055424312292839145, 0.0545423204111489, 0.13797681811382614, 0.047101535858997214, 0.01195448708104166, 0.11836561446926909, 0.9244023295350992, 0.03711469305035049, 1.0, 0.07548705924540329, 0.7318371651085306, 0.9731361774985118, 0.869822772159487, 0.9741432035280754], [0, 0, 0, 1]]\n",
      "[[0.08045826950863516, 0.09169395390334355, 0.0946972602751293, 0.06656882164633901, 0.03484835735264566, 0.11043355914379202, 0.10440901598802096, 0.019309892013101848, 0.9528504323418276, 0.005634319273625482, 0.7818586769819807, 0.02245943559938654, 0.9693090794509227, 0.8308078933108073, 0.9310836815240141, 1.0], [0, 0, 0, 1]]\n",
      "[[0.1517498178094279, 0.09363951548691175, 0.0, 0.07746131016990429, 0.030445231977207637, 0.06529465215333326, 0.1328523878675104, 0.11984659323199932, 0.8175367981359007, 0.10517360561657961, 1.0, 0.11367892833136155, 0.7670735245592519, 1.0, 0.9295633300755304, 0.9900489110344275], [0, 0, 0, 1]]\n",
      "[[0.09130448928774362, 0.0784272178870386, 0.04130474716159706, 0.04809648537200642, 0.1325908006545583, 0.16296870428545066, 0.14100529684868535, 0.1091866095714735, 0.8587768072260485, 0.07908408678767201, 0.8718913161118979, 0.06957009986874785, 0.7286968982659179, 0.989124211979566, 0.7942874209384037, 0.7646812770268365], [0, 0, 0, 1]]\n",
      "[[0.13718192860669057, 0.11751830800970592, 0.1000226218057906, 0.051018314868349915, 0.04039531545269476, 0.17159905506377193, 0.11171232485353698, 0.09647649546133183, 1.0, 0.18202873468826147, 0.9314517139228663, 0.03075802620626321, 0.9003498040894826, 0.9451131257601874, 0.8996893388348565, 0.848115811120142], [0, 0, 0, 1]]\n",
      "[[0.08261062296891275, 0.09401574834616197, 0.09059514414471588, 0.017359513187569273, 0.07181485403917885, 0.10861628755731845, 0.11215284308540237, 0.11745856651902234, 0.1561024713310095, 0.6496953737166646, 0.09225733881289946, 0.9000458320384112, 0.8977200639870497, 0.8301336226002327, 0.8069484748188218, 0.9611844461429787], [0, 0, 0, 1]]\n",
      "[[0.15591089139474368, 0.06364475599862286, 0.1284030063819052, 0.16921203206545582, 0.07194896758454003, 0.14350311422012615, 0.06578322186024194, 0.0018377099802655839, 0.08766282390530479, 0.8474916933098571, 0.09618854041826708, 0.8669416523287329, 0.7736179899706241, 0.8039251065538827, 0.8156092468222262, 0.8835665918823923], [0, 0, 0, 1]]\n",
      "[[0.06284381326703598, 0.09247155861723592, 0.11270093808637383, 0.11426827551599787, 0.0412277482682856, 0.09256765415529802, 0.08130058443985493, 0.16200771451477336, 0.08654162443600091, 0.8601802924122212, 0.1241323925567268, 0.9846835795296076, 0.7957343108711259, 0.737683572342055, 0.9936654729102611, 0.7839530039813476], [0, 0, 0, 1]]\n",
      "[[0.016770883042044743, 0.1593194614222588, 0.07677722790922555, 0.13345914418708305, 0.19273482318128043, 0.09360678465123919, 0.18035701875955515, 0.12928670220634852, 0.09942339216185486, 0.9491271262839053, 0.01032112131977296, 0.7000589011122649, 1.0, 0.8516024727832431, 1.0, 0.7863035986985316], [0, 0, 0, 1]]\n",
      "[[0.10102804424059458, 0.0890210200804623, 0.07465629402198039, 0.05894015327087212, 0.12334533566473947, 0.05995182967202924, 0.14513543713603694, 0.06344713433090544, 0.04350616352619699, 0.9915395881473834, 0.13818613986729525, 0.7462174987049348, 0.9338359754574372, 0.7191560012615845, 0.841925903327545, 0.9226198333979182], [0, 0, 0, 1]]\n",
      "[[0.13109998040276333, 0.0455408576793237, 0.15587946762948993, 0.15481507801638164, 0.18321787913013632, 0.1138419931473802, 0.051713055051804784, 0.1474708336066951, 0.044304392043841956, 0.8848801143586057, 0.11619102904427117, 0.9264862161637178, 0.910670884083153, 0.858348920040894, 0.9400629775850649, 0.9926880983916843], [0, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "results = generate_data( clean_data, 10)\n",
    "for result in results:\n",
    "    print( result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each type (all four terrains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = generate_data( clean_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `learn_model` to learn a ANN model for classifying sensor images as hills, swamps, plains or forest. **Set Verbose to True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.500, error=185.480\n",
      ">epoch=1, lrate=0.500, error=81.251\n",
      ">epoch=2, lrate=0.500, error=81.404\n",
      ">epoch=3, lrate=0.500, error=80.685\n",
      ">epoch=4, lrate=0.500, error=79.396\n",
      ">epoch=5, lrate=0.500, error=77.219\n",
      ">epoch=6, lrate=0.500, error=74.388\n",
      ">epoch=7, lrate=0.500, error=71.191\n",
      ">epoch=8, lrate=0.500, error=67.488\n",
      ">epoch=9, lrate=0.500, error=63.373\n",
      ">epoch=10, lrate=0.500, error=59.291\n",
      ">epoch=11, lrate=0.500, error=55.398\n",
      ">epoch=12, lrate=0.500, error=51.721\n",
      ">epoch=13, lrate=0.500, error=48.393\n",
      ">epoch=14, lrate=0.500, error=45.497\n",
      ">epoch=15, lrate=0.500, error=43.036\n",
      ">epoch=16, lrate=0.500, error=40.989\n",
      ">epoch=17, lrate=0.500, error=39.248\n",
      ">epoch=18, lrate=0.500, error=37.634\n",
      ">epoch=19, lrate=0.500, error=35.845\n",
      ">epoch=20, lrate=0.500, error=33.551\n",
      ">epoch=21, lrate=0.500, error=30.862\n",
      ">epoch=22, lrate=0.500, error=28.151\n",
      ">epoch=23, lrate=0.500, error=25.433\n",
      ">epoch=24, lrate=0.500, error=22.693\n",
      ">epoch=25, lrate=0.500, error=20.111\n",
      ">epoch=26, lrate=0.500, error=17.770\n",
      ">epoch=27, lrate=0.500, error=15.628\n",
      ">epoch=28, lrate=0.500, error=13.733\n",
      ">epoch=29, lrate=0.500, error=12.157\n",
      ">epoch=30, lrate=0.500, error=10.821\n",
      ">epoch=31, lrate=0.500, error=9.685\n",
      ">epoch=32, lrate=0.500, error=8.739\n",
      ">epoch=33, lrate=0.500, error=7.955\n",
      ">epoch=34, lrate=0.500, error=7.288\n",
      ">epoch=35, lrate=0.500, error=6.708\n",
      ">epoch=36, lrate=0.500, error=6.195\n",
      ">epoch=37, lrate=0.500, error=5.737\n",
      ">epoch=38, lrate=0.500, error=5.326\n",
      ">epoch=39, lrate=0.500, error=4.955\n"
     ]
    }
   ],
   "source": [
    "model = learn_model( train_data, 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_data` to generate 100 blurred examples of each terrain and use this as your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = generate_data( clean_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the model and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled is False\n",
      "[[(1, 0.9084647430747597), (0, 4.507782191901658e-05), (0, 0.0735083765330385), (0, 0.17137325607128281)], [(1, 0.9504439925593112), (0, 3.0877212242421666e-05), (0, 0.13846081723290096), (0, 0.07154558136254616)], [(1, 0.9334329621754337), (0, 3.7808459053354616e-05), (0, 0.11391169588740958), (0, 0.09879092266717796)], [(1, 0.9171758648155078), (0, 4.2764759333320396e-05), (0, 0.08238602765963231), (0, 0.14892103691510483)], [(1, 0.9175432723873012), (0, 4.1701472765342526e-05), (0, 0.08081416604678998), (0, 0.14879788429918073)]]\n",
      "\n",
      "Labeled is True\n",
      "[[(1, 1), (0, 0), (0, 0), (0, 0)], [(1, 1), (0, 0), (0, 0), (0, 0)], [(1, 1), (0, 0), (0, 0), (0, 0)], [(1, 1), (0, 0), (0, 0), (0, 0)], [(1, 1), (0, 0), (0, 0), (0, 0)]]\n"
     ]
    }
   ],
   "source": [
    "results = apply_model( model, test_data,False)\n",
    "print('Labeled is False')\n",
    "print(results[:5])\n",
    "\n",
    "\n",
    "print('\\nLabeled is True')\n",
    "results = apply_model( model, test_data,True)\n",
    "print(results[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print( results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're pretty sure your algorithm works (the error rate during training is going down, and you can evaluate `apply_model` results for its error rate), you need to determine what the best number of hidden nodes is.\n",
    "\n",
    "Try 2, 4, or 8 hidden nodes and indicate the best one. Follow the outline above under \"Simple Evaluation\".\n",
    "In the \"real world\", you could 10 fold cross validation and validation curves to determine the number of hidden nodes and possibly if you needed one or two hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `error_rate()`\n",
    "Provided the formatting of the results data, the `error_rate` function scans through the list of tuples for each observation. Whenever a component of the tuples is different from the other, that observation is counted as an error. The error rate is the result of that count divided by the total observations in the `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(results):\n",
    "    errors = 0 \n",
    "    for result in results:\n",
    "        for lable in result:\n",
    "            if lable[0] != lable[1]:\n",
    "                errors += 1\n",
    "                break\n",
    "    return errors/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate on Training and Test Data\n",
      "at 30 epochs and a learning rate of 0.5 \n",
      "\n",
      "Nodes Training (%)      Test (%)\n",
      "2        9.2593         9.4118\n",
      "3        9.2593         9.4118\n",
      "4        9.2593         9.4118\n",
      "5        9.2593         9.4118\n",
      "6        9.2593         9.4118\n",
      "7        9.2593         9.4118\n",
      "8        9.2593         9.4118\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "l_rate = 0.5\n",
    "nodes_label = 'Nodes'\n",
    "train_label = 'Training (%)'\n",
    "test_label = 'Test (%)'\n",
    "print('Error Rate on Training and Test Data')\n",
    "print(f'at {epochs} epochs and a learning rate of {l_rate} \\n')\n",
    "print(f\"\"\"{nodes_label : <5}{train_label : ^15}\\\n",
    "    {test_label : >6}\"\"\")\n",
    "\n",
    "train_data = generate_data(clean_data, 200)\n",
    "random.shuffle(train_data)\n",
    "test_data = generate_data(clean_data, 40)\n",
    "random.shuffle(test_data)\n",
    "for hidden_nodes in range(2,9):\n",
    "    \n",
    "    model=None\n",
    "    train_error = 0\n",
    "    test_error = 0\n",
    "    \n",
    "    model = learn_model( train_data, hidden_nodes, False, n_epoch = epochs, l_rate=l_rate)\n",
    "    \n",
    "    train_results = apply_model(model, train_data,True)\n",
    "    train_error = error_rate(train_results)*100\n",
    "    \n",
    "    test_results = apply_model(model, test_data,True)\n",
    "    test_error = error_rate(test_results)*100\n",
    "    \n",
    "    print(f\"\"\"{hidden_nodes : <5}{train_error : ^15.4f}\\\n",
    "    {test_error : >6.4f}\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which number of hidden nodes is best? ____\n",
    "\n",
    "**After trying different combinations and variables, holding the same amount of epochs and learning rate while changing the number of nodes in the internal layer does not seem to have a hugely significant impact. It is the case that the error rate decreases as the number of nodes in the internal layer increases. However, changing the learning rate increases the speed at which the algorithm converges. Increasing the amount of epochs increases the ability the algorithm has to improve accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
